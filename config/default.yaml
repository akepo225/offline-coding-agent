# Default Configuration for Offline Coding Agent

# Model Settings
model:
  name: "Qwen2.5-Coder-7B-Instruct-Q4_K_M.gguf"
  path: "./models"

# Inference Settings - Adjust based on your hardware
inference:
  # Context window size (tokens)
  # - Low-end (8GB RAM): 2048
  # - Mid-range (16GB RAM): 4096
  # - High-end (32GB+ RAM): 8192-16384
  n_ctx: 4096

  # CPU threads (0 = auto-detect)
  # - Set to 0 for auto-detection
  # - Or manually set to your CPU core count for optimal performance
  n_threads: 0

  # Batch size for prompt processing
  # - Low-end: 256
  # - Mid-range: 512
  # - High-end: 1024
  n_batch: 512

  # Maximum tokens to generate per response
  # - Low-end/Fast: 512
  # - Balanced: 1024
  # - High-quality/Slow: 2048-4096
  max_tokens: 1024

  # Temperature (0.0-1.0) - Controls randomness
  # - Code generation: 0.2-0.3 (more deterministic)
  # - General tasks: 0.5-0.7 (balanced)
  # - Creative tasks: 0.8-1.0 (more creative)
  temperature: 0.3

  # Top-p sampling (0.0-1.0) - Nucleus sampling
  # - More focused: 0.8-0.9
  # - More diverse: 0.95-1.0
  top_p: 0.9

  # Repeat penalty (1.0-1.5) - Prevents repetition
  # - No penalty: 1.0
  # - Light penalty: 1.1
  # - Strong penalty: 1.3-1.5
  repeat_penalty: 1.1

  # Model verbosity (true/false) - Shows llama.cpp logs
  verbose: false

# CLI Settings
cli:
  output_format: "text"  # text, json
  verbose: false
  streaming: false  # Future feature

# Context Management
context:
  cache_enabled: true
  cache_directory: "./cache"
  max_cache_size_mb: 100
  file_extensions:
    - ".py"
    - ".js"
    - ".ts"
    - ".jsx"
    - ".tsx"
    - ".java"
    - ".cpp"
    - ".c"
    - ".h"
    - ".cs"
    - ".go"
    - ".rs"
    - ".php"
    - ".rb"
    - ".swift"
    - ".kt"
    - ".scala"
    - ".r"
    - ".sql"
    - ".sh"
    - ".bat"
    - ".ps1"
    - ".html"
    - ".css"
    - ".scss"
    - ".less"
    - ".json"
    - ".yaml"
    - ".yml"
    - ".xml"
    - ".toml"
    - ".ini"
    - ".md"
    - ".txt"

# File Handling
files:
  max_file_size_mb: 10
  exclude_patterns:
    - "node_modules/"
    - ".git/"
    - "__pycache__/"
    - "*.pyc"
    - ".vscode/"
    - ".idea/"
    - "build/"
    - "dist/"
    - ".DS_Store"
    - "*.log"
    - "*.tmp"

# Performance
performance:
  model_keep_alive: true
  max_concurrent_requests: 1
  response_timeout_sec: 30
  preload_model: true

# Output Formatting
output:
  show_thinking: false
  show_confidence: false
  show_sources: true
  max_line_length: 120
  syntax_highlighting: true